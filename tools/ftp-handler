#!/usr/bin/env ruby
$LOAD_PATH.unshift File.expand_path(File.join(File.dirname(__FILE__), "../lib"))

require 'rubygems'
require 'offin/packages'
require 'offin/db'
require 'offin/config'
require 'watch-queue/watch-utils'
require 'watch-queue/watch-directory'

## TODO: use a logger pointing to STDERR instead of just writing to it
## (so we can assign/ignore severity levels)

# Note: ftp-handler is run as an independent front end for our
# queueing system, so it isn't directly running resque worker code, as
# is the ingest-handler.
#
# It *is* started and watched by the 'god' process manager (as is
# ingest-handler) however.
#
# All this is to say that our logging must be different from
# ingest-handler (which uses Resque::Logger). For now, we simply write
# to STDERR, which gets captured by the process manager and logged.

REREAD = 60 * 5   # re-read config file this often
PAUSE  = 5        # PAUSE must divide REREAD evenly

SYSTEM_ERROR_SLEEP    = 60
UNHANDLED_ERROR_SLEEP = 600

def loop_for_incoming config_file
  counter = 0

  while true

    # maybe re-read the config file:

    if (counter % REREAD == 0)

      if counter == 0
        STDERR.puts "INFO: reading configuration file #{config_file}"
      else
        STDERR.puts "INFO: rereading configuration file #{config_file}"
      end

      watched_directories = watch_configured_directories(config_file)
    end

    # check for incoming packages on all watched directories

    watched_directories.each { |wd| wd.enqueue_incoming_packages }

    # keep track of when to re-read the config file

    sleep PAUSE
    counter += PAUSE
  end
end

# Search through various website stanzas in the config file for
# declaration of ftp_root; do sanity check and collect up all configs
# that refer to a valid ftp_site.  Also check for system digitool
# directory.  We re-read the configuation file every time we're
# called, to catch changes.

def watch_configured_directories  config_file

  watched_directories = []

  config = Datyl::Config.new(config_file, 'default')

  if config.digitool_root
    errors = WatchUtils.directory_problems(config.digitool_root)
    if errors.empty?
      STDERR.puts "INFO: Watching digitool incoming directory in #{config.digitool_root}"
      watched_directories.push DigiToolWatchDirectory.new(config)
    else
      STDERR.puts "ERROR: Skipping watching DigiTool directory #{config.digitool_root}, these configuration errors were encountered:"
      errors.each { |line| STDERR.puts "ERROR: " + line }
    end
  end

  config.all_sections.each do |section|

    site_config = Datyl::Config.new(config_file, 'default', section)
    next unless site_config.ftp_root
    errors = WatchUtils.directory_problems(site_config.ftp_root)

    if errors.empty?
      STDERR.puts "INFO: Watching FTP incoming directory in #{site_config.ftp_root} for #{section}"
    else
      STDERR.puts "ERROR: Skipping watching FTP directory #{site_config.ftp_root} for #{section}, these configuration errors were encountered:"
      errors.each { |line| STDERR.puts "ERROR: " + line }
      next
    end
    watched_directories.push FtpWatchDirectory.new(site_config, section)
  end

  return watched_directories.compact
end

# The 'god' process monitor will restart an instance of this script
# when we exit on error.

begin

  config = WatchUtils.setup_config()
  WatchUtils.setup_redis_connection(config)
  WatchUtils.setup_ingest_database(config)
  loop_for_incoming(config.path)

rescue Redis::CannotConnectError, SystemError => e

  STDERR.puts "ERROR: #{e.message}; sleeping for #{SYSTEM_ERROR_SLEEP} seconds."
  sleep SYSTEM_ERROR_SLEEP
  exit

rescue => e

  STDERR.puts "ERROR: Unhandled #{e.class}: #{e.message}; sleeping for #{UNHANDLED_ERROR_SLEEP/60} minutes.  Backtrace follows:"
  e.backtrace.each { |line| STDERR.puts "ERROR: " + line }
  sleep UNHANDLED_ERROR_SLEEP
  exit
end
